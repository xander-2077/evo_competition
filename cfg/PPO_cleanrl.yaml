algo_name: PPO_cleanrl    # PPO
env_id: "robo-sumo-ants-v0"
seed: 1
torch_deterministic: True
cuda: True
save_model: True
exp_name: ${algo_name}
render_mode: None   # None, human, rgb_array, rgb_array_float

# Algorithm specific arguments
total_timesteps: 166666667
num_envs: 50  # 50000/num_steps 
num_steps: 1000  # 500, 1000
num_minibatches: 25  # batchsize/2000
update_epochs: 6

learning_rate: 0.001
anneal_lr: True
gamma: 0.99
gae_lambda: 0.95
norm_adv: True
clip_coef: 0.2
clip_vloss: True
ent_coef: 0.0  # 0.1
vf_coef: 0.5
max_grad_norm: 0.5
target_kl: None

# to be filled in runtime
batch_size: 50000
minibatch_size: 2000
num_iterations: 0
iteration_alpha_anneal: 500

save_model_interval: 10


hydra:
  job:
    chdir: true
  run:
    dir: ./runs/${env_id}/${now:%m-%d_%H-%M}_${algo_name}